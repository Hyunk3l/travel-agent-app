name: Tests

on:
  push:
    branches:
      - master
      - main
  pull_request:
  workflow_dispatch:
    inputs:
      run_integration:
        description: "Run integration tests (requires Ollama)"
        required: false
        default: "false"

jobs:
  pytest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: pip
          cache-dependency-path: pyproject.toml
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e '.[dev]'
      - name: Run tests
        run: pytest -m "not integration"

  integration:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && inputs.run_integration == 'true' || github.event_name != 'workflow_dispatch' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: pip
          cache-dependency-path: pyproject.toml
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e '.[dev]'
      - name: Install Ollama
        run: curl -fsSL https://ollama.com/install.sh | sh
      - name: Start Ollama
        run: |
          nohup ollama serve > ollama.log 2>&1 &
          for i in {1..30}; do
            if curl -fsS http://127.0.0.1:11434/api/tags > /dev/null; then
              echo "Ollama is up"
              break
            fi
            sleep 1
          done
      - name: Pull model
        run: ollama pull llama3.1
      - name: Run integration tests
        env:
          RUN_INTEGRATION: "1"
          OLLAMA_HOST: http://127.0.0.1:11434
          OLLAMA_MODEL: llama3.1
        run: pytest -m "integration"
